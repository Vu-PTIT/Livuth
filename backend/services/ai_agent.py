"""
AI Agent Service using Google Gemini
Handles all interactions with the LLM.
"""
import google.generativeai as genai
from backend.core.config import settings

class AIAgent:
    """Agent for handling AI interactions via Google Gemini"""
    
    # Default System Prompt
    DEFAULT_SYSTEM_PROMPT = """Ch√†o b·∫°n! T√¥i l√† Ganvo AI - Tr·ª£ l√Ω du l·ªãch th√¥ng minh chuy√™n v·ªÅ VƒÉn h√≥a v√† L·ªÖ h·ªôi Vi·ªát Nam üáªüá≥.

    T√¥i ·ªü ƒë√¢y ƒë·ªÉ gi√∫p b·∫°n:
    - Kh√°m ph√° c√°c l·ªÖ h·ªôi ƒë·∫∑c s·∫Øc tr√™n kh·∫Øp c·∫£ n∆∞·ªõc üèÆ
    - T√¨m ki·∫øm ƒë·ªãa ƒëi·ªÉm du l·ªãch vƒÉn h√≥a, t√¢m linh, l·ªãch s·ª≠ 
    - G·ª£i √Ω l·ªãch tr√¨nh v√† kinh nghi·ªám ƒëi l·∫°i, ƒÉn u·ªëng üçú
    - Gi·∫£i ƒë√°p th·∫Øc m·∫Øc v·ªÅ phong t·ª•c, t·∫≠p qu√°n Vi·ªát Nam

    H√£y h·ªèi t√¥i b·∫•t c·ª© ƒëi·ªÅu g√¨ v·ªÅ du l·ªãch Vi·ªát Nam nh√©! T√¥i s·∫Ω tr·∫£ l·ªùi ng·∫Øn g·ªçn, ch√≠nh x√°c v√† th√¢n thi·ªán."""

    def __init__(self):
        self.model = None
        self._setup_gemini()

    def _setup_gemini(self):
        """Configure and initialize Gemini model"""
        if settings.GEMINI_API_KEY:
            genai.configure(api_key=settings.GEMINI_API_KEY)
            self.model = genai.GenerativeModel(
                model_name=settings.GEMINI_MODEL,
                generation_config={
                    "temperature": settings.GENERATION_TEMPERATURE,
                    "top_p": 0.95,
                    "top_k": 40,
                    "max_output_tokens": 4096,
                }
            )

    def get_response(self, user_message: str, history: list = None) -> str:
        """
        Get response from AI based on user message and chat history.
        
        Args:
            user_message: The current message from user
            history: List of previous messages in Gemini format
            
        Returns:
            AI response text
        """
        if not self.model:
            return "Xin l·ªói, tr·ª£ l√Ω AI ch∆∞a ƒë∆∞·ª£c c·∫•u h√¨nh. Vui l√≤ng li√™n h·ªá qu·∫£n tr·ªã vi√™n."

        try:
            # Start chat session
            chat = self.model.start_chat(history=history or [])
            
            # If no history, inject system prompt with the first message
            if not history:
                prompt = f"{self.DEFAULT_SYSTEM_PROMPT}\n\nUser: {user_message}"
                response = chat.send_message(prompt)
            else:
                response = chat.send_message(user_message)
                
            return response.text
            
        except Exception as e:
            import traceback
            print(f"Gemini API Error: {str(e)}")
            print(traceback.format_exc())
            return "Xin l·ªói, t√¥i kh√¥ng th·ªÉ tr·∫£ l·ªùi ngay b√¢y gi·ªù. Vui l√≤ng th·ª≠ l·∫°i sau."
